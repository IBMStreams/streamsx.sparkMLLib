<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en-us" lang="en-us">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="copyright" content="(C) Copyright 2005"/>
<meta name="DC.rights.owner" content="(C) Copyright 2005"/>
<meta name="DC.Type" content="reference"/>
<meta name="DC.Title" content="Developing and running applications that use the SparkMLLib Toolkit"/>
<meta name="DC.Format" content="XHTML"/>
<meta name="DC.Identifier" content="spldoc_page"/>
<link rel="stylesheet" type="text/css" href="../../html/commonltr.css"/>
<link rel="stylesheet" type="text/css" href="../../html/spldoc.css"/>
<title>Developing and running applications that use the SparkMLLib Toolkit</title>
</head>
<body id="spldoc_page">


<h1 class="title topictitle1">Developing and running applications that use the SparkMLLib Toolkit</h1>

<div class="body refbody">
<div class="section">
<p class="p">
<a class="xref" href="../toolkits/toolkits.html">IBMStreams streamsx.sparkMLLib Toolkit</a> &gt; <a class="xref" href="tk$com.ibm.streamsx.sparkmllib.html">com.ibm.streamsx.sparkmllib 1.1.1</a> &gt; Developing and running applications that use the SparkMLLib Toolkit</p>

</div>


<div class="section">
<p class="p">To create applications that use the SparkMLLib Toolkit, you must configure either Streams Studio or the SPL compiler to be aware of the location of the toolkit. 
</p>

</div>

<div class="section"><h2 class="title sectiontitle">Before you begin
</h2>

<div class="p">
<ul class="ul">
<li class="li"> Install IBM InfoSphere Streams.  Configure the product environment variables by entering the following command: 
<pre class="pre codeblock">
  source product-installation-root-directory/4.0.1.0/bin/streamsprofile.sh
</pre>

</li>

<li class="li"> Install a version of Apache Spark 1.4.0+ and set the SPARK_HOME environment variable to the location where Spark is installed. Note that SPARK_HOME must be set on all nodes of the Streams cluster where a SparkMLLib operator can run.</li>

<li class="li"> Generate a Spark model as described in the next section and save it to the local filesystem or HDFS.</li>

</ul>

</div>

</div>

<div class="section"><h2 class="title sectiontitle">Spark Models
</h2>

<p class="p">This toolkit provides a number of operators that can load a stored Spark MLlib model and use it to perform real time scoring on incoming tuple data. 
</p>

<p class="p">For example, the SparkCollaborativeFilteringALS operator can load a Spark collaborative filtering model (of type MatrixFactorizationModel in the Spark API). In order for the operator to be able to use this model within Streams, the Spark program that created the original model must store the model. The following scala code demonstrates how the model can be saved to HDFS:
</p>

<div class="p">
<pre class="pre codeblock">
	//Generate a MatrixFactorizationModel by training against test data
	val model = ALS.train(training, rank, numIter, lambda)
	
	//Save the generated model to the filesystem
	model.save(sparkContext, "hdfs://some/path/my_model")
</pre>


</div>

<p class="p">Once the model has been persisted, the path to the persisted model would be passed in as a parameter to the SparkCollaborativeFilteringALS operator. The following code  demonstrates how this would be done in the SPL program:
</p>

<div class="p">
<pre class="pre codeblock">
(stream&lt;int32 user, int32 counter, list&lt;int32&gt; analysisResult&gt; SparkCollaborativeFilteringALSOut) as
		SparkCollaborativeFilteringALSOp1 =
		SparkCollaborativeFilteringALS(InputPort1)
	{
		param
			analysisType : RecommendProducts ;
			attr1 : Beacon_1_out0.user ;
			attr2 : Beacon_1_out0.counter ;
			modelPath : "hdfs://some/path/my_model" ;
	}
</pre>


</div>

<p class="p">On initialization, the operator will load the model. Each incoming tuple will be used to generate a score using the model and the score would be passed as an attribute called 'analysisResult' on the output schema.
</p>

</div>

<div class="section"><h2 class="title sectiontitle">About this task
</h2>

<p class="p">After the location of the toolkit is communicated to the compiler, the SPL artifacts that are specified in the toolkit can be used by an application. The application can include a use directive to bring the necessary namespaces into scope. Alternatively, you can fully qualify the operators that are provided by toolkit with their namespaces as prefixes.
</p>

</div>

<div class="section"><h2 class="title sectiontitle">Procedure
</h2>

<div class="p">
<ol class="ol">
<li class="li"> Verify that the SPARK_HOME environment variable is set as described above.</li>

<li class="li"> Make sure that a trained Spark model has been saved to the local file system or on HDFS.</li>

<li class="li"> Configure the SPL compiler to find the toolkit root directory. Use one of the following methods:
<ul class="ul">
<li class="li"> Set the <strong class="ph b">STREAMS_SPLPATH</strong> environment variable to the root directory of a toolkit or multiple toolkits (with : as a separator).     For example:
<pre class="pre codeblock">
  export STREAMS_SPLPATH=$STREAMS_INSTALL/toolkits/com.ibm.streamsx.sparkmllib
</pre>

</li>

<li class="li"> Specify the <strong class="ph b">-t</strong> or <strong class="ph b">--spl-path</strong> command parameter when you run the <strong class="ph b">sc</strong> command. For example:
<pre class="pre codeblock">
  sc -t $STREAMS_INSTALL/toolkits/com.ibm.streamsx.sparkmllib -M MyMain
</pre>

    where MyMain is the name of the SPL main composite.     <strong class="ph b">Note</strong>: These command parameters override the <strong class="ph b">STREAMS_SPLPATH</strong> environment variable.</li>

<li class="li"> Add the toolkit location in InfoSphere Streams Studio.</li>

</ul>
</li>

<li class="li"> Develop your application. </li>

<li class="li"> Build your application.  You can use the <strong class="ph b">sc</strong> command or Streams Studio.  </li>

<li class="li"> Start the InfoSphere Streams instance. </li>

<li class="li"> Run the application. You can submit the application as a job by using the <strong class="ph b">streamtool submitjob</strong> command or by using Streams Studio. </li>

</ol>

</div>

</div>

</div>


</body>
</html>