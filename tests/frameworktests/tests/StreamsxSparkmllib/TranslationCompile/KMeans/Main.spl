
use com.ibm.streamsx.sparkmllib.clustering::SparkClusteringKMeans ;

public composite Main
{
	graph
		(stream<float64 x, float64 y> FileSource_3_out0) as FileSource_3 = FileSource()
		{
			param
				file : dataDirectory() + "/random_2d.csv" ;
		}

//<1>		(stream<rstring analysisResul> SparkClusteringKMeans_3_out0) as
//<0>		(stream<rstring analysisResult> SparkClusteringKMeans_3_out0) as
			SparkClusteringKMeans_3 = SparkClusteringKMeans(Functor_4_out0)
		{
			param
				testDataAttr : testData ;
				modelPath : getApplicationDir() + "/etc/kmeans_model" ;
		}

		(stream<list<float64> testData> Functor_4_out0) as Functor_4 =
			Functor(FileSource_3_out0 as inputStream)
		{
			output
				Functor_4_out0 : testData = [x,y ] ;
		}

		() as FileSink_5 = FileSink(SparkClusteringKMeans_3_out0)
		{
			param
				file : dataDirectory() + "/output.txt" ;
				flush:1u;
		}
}
